# 🧰 GPT 語言模型使用指南（工程師版本）

> 本指南整合語用策略、系統認知與提示語設計，目的是讓工程師能有效操作 GPT 模型，提升對話質量、控制幻覺風險並精確取得內容。

---

## 🧭 GPT 問題分類與能力邊界（能力判定）

| 問題類型                           | GPT 能答？ | 技術說明                                                         |
|------------------------------------|------------|------------------------------------------------------------------|
| 抽象定義、邏輯分類、概念建構           | ✅ 高可信   | 大量語料支持，可生成分類樹與比較結構                                         |
| 程式碼撰寫、框架整合、錯誤追蹤         | ✅ 中可信   | 有效範例建構，但常見語法錯誤與 API 混淆，需人工驗證                                 |
| 網頁動態內容擷取（如分享連結內文）       | ❌ 不可用   | 模型無瀏覽器與 JS 執行環境，無法渲染前端後台生成頁面                            |
| 即時事件、當日資料                     | ❌（除非外部插件） | 模型本體為訓練資料，無法即時查詢；依賴工具插件時仍受制於解析器與 API 接口                |
| 統計推論、資料視覺化（使用 code interpreter） | ✅ 高可信   | 若有 python 模組，可進行真實計算與繪圖，精度依賴內部 sandbox 限制與支援套件版本            |

---

## ⚠️ 語言風險辨識與預警系統

### 常見 GPT 幻覺模式與偵測語句

| 風險模式               | 偵測用語                                    | 應對策略                                                       |
|------------------------|---------------------------------------------|----------------------------------------------------------------|
| 自信錯誤               | "這是正確的..." 但未提供來源                   | 提示："請提供資料來源或說明此說法的訓練依據"                               |
| 引用偽造               | GPT 編出看似真實但不存在的文獻或網頁             | 行為：主動搜尋驗證引用連結或請求 GPT 自我標記「推測 vs 出處」                 |
| 邏輯跳接               | 回答中出現未提及的假設前提                     | 提示："請逐步推論並標示每一個前提及其來源"                             |
| 跨語境誤用             | 將某領域概念誤植至不適用語境                   | 檢查：語詞的上下文是否與原學科一致、比對定義詞源                             |
| 記憶污染               | 使用到先前對話中未明示的錯誤知識或過時設定         | 提示："請只根據本次對話資訊作答，不得引用未知上下文"                         |

---

## 🧾 Prompt 設計模板（語用與邏輯導向）

### 結構分類型
```
請將「___」這個主題整理為：
- 多層分類（標題、副標題）
- 表格對照（定義、例子、易混淆點）
- 對比關係（A vs B vs C）
```

### 識別事實與生成內容
```
以下內容請標註：
- ✅ 可驗證事實
- ❓ 推論過程（請說明前提）
- ✨ 語言生成（例子、隱喻、比喻）
```

### 專業推論驗證流程
```
請依照以下格式作答：
1. 確認問題條件（列舉所有變數與假設）
2. 逐步推論每個邏輯段落
3. 標註不確定性（高/中/低）
4. 回傳可信度與推理強度標記
```

---

## 📊 系統認知補充（工程師向）

### Prompt 處理流程概念圖

```
Prompt → Token 分詞 → Prefix Injection (System Prompt)
→ 模型推論（推測下一 token）→ 回傳結果（包含生成、限制條件）
```

### Context 與記憶區分

- Context window（目前對話記憶）：最多約 128k token（視模型而定）
- Memory（長期記憶）：需顯性啟用，並由 OpenAI 系統管理，不可直接讀寫
- Plugin 與 tool 使用時 context 整合為「延後補發 prompt」行為，並非即時記憶

---

## 📌 補充技巧與實用設計

- **雙重提示（反預設）**：在同一 prompt 中說「你不能做 A」，再立即請他做 A，用以檢測幻覺界限
- **格式鎖定**：要求回傳特定語言結構（如 Markdown 表格、JSON、流程圖）以利機器判讀或後處理
- **記憶區隔**：主動提示「請忽略之前所有上下文」，強制模型重置狀態（有效但非保證）

---

## ✅ 使用者語用行為建議

- **不要假設模型有「通用理解力」**──它只有語料趨勢推測力
- **強迫模型說明「為什麼知道」比「說得好聽」更重要**
- **所有生成都需經人工驗證，GPT 本身不具備事實責任**

---

## 🔚 附錄：可信度標記建議格式（回饋用）

```
[可信度: 高｜中｜低]
[推理強度: 事實｜推論｜假設｜生成]
```

> 建議所有複雜生成任務均附加此標記作為風險管理與回溯依據
