# 🧭 GPT 使用判斷三步驟（非工程背景者適用）

## ✅ STEP 1：問題類型分類 → 判斷 GPT 能否回答

| 問題類型                         | GPT 能答？ | 解釋                                                                 |
|----------------------------------|------------|----------------------------------------------------------------------|
| 概念理解（如「民主是什麼？」）     | ✅ 高信賴   | 基於龐大語料統計，可給出多角度、合理描述                                     |
| 歷史、文學、哲學分析             | ✅ 可用     | 可用來探索觀點，但須自行判斷合理性（容易混合事實與詮釋）                       |
| 軟體開發／寫程式                 | ✅ 但要驗證 | GPT 會生成「看起來像能跑」的程式，但常含錯誤，需具備驗證工具（如測試程式）             |
| 目前網頁內容／分享頁面資料         | ❌ 無法直接讀取 | 無 JS/瀏覽器能力，無法從連結中擷取真實資料，除非你貼給我原始內容                   |
| 時事／今天發生什麼事              | ❌（除非使用插件） | 離線模型無即時資訊，會憑過去資料生成看起來合理的猜測                           |
| 主觀選擇題（如「我要不要換工作？」） | ❌ 無法判斷  | GPT 無個人意志，也無法理解你現實的全部條件，建議當作「他人意見的一種」處理           |

---

## ⚠️ STEP 2：語言風險辨識 → 識破 GPT 的「自信幻覺」

| GPT 可能產生幻覺的跡象             | 對應警訊處理                                             |
|------------------------------|------------------------------------------------------|
| 語氣非常自信，卻無資料來源         | 詢問：「你是依據哪一份資料說的？這是事實還是統計模型生成？」                 |
| 回答邏輯跳躍、沒有過程           | 詢問：「請你一步一步說明你的推論過程」                               |
| 說「我能打開某個連結」「我讀到你的檔案」 | 認定為錯誤：GPT 實際上**無法抓取任何網頁資料，也無法直接讀取檔案內容**         |
| 提供引用、但點進去不對           | 常見幻覺：GPT 偽造了文獻或出處，需用外部搜尋工具查驗                          |

---

## 🛠️ STEP 3：對話設計策略 → 讓 GPT 更可靠

| 你的需求                 | 對應提示語設計（Prompt Engineering）                                 |
|--------------------------|------------------------------------------------------------------|
| 想知道某問題的分類或結構     | 「請用分類圖、表格、步驟流程來解釋這個問題」                              |
| 想知道哪裡有問題             | 「請幫我用紅筆標出這段話可能邏輯不清的地方，並說明為什麼」                        |
| 想請 GPT 幫我推論某個情況     | 「先列出這個問題的所有已知條件，再推論可能結果」                                |
| 想避免幻覺／誤導            | 「請只根據你最有信心的知識回答，若不確定請說你不確定」                            |
| 想讓 GPT 幫我抓住語言錯誤     | 「幫我檢查這段話邏輯是否自洽、有無模糊、用詞是否一致，標示問題並解釋原因」                |

---

## 📌 小總結：非工程者使用 GPT 的安全守則

- 「這是 GPT 根據語料就能答的事嗎？還是它需要真的看過什麼或知道現在的狀況？」
- 「這回答我有沒有其他方法交叉驗證？」
- 「它說得好聽，但有沒有可能是統計錯誤？」

GPT 不是萬能助手，而是語言模仿器。會說 ≠ 會做；說得好聽 ≠ 說得正確。
你不用懂程式，也能駕馭 GPT，只要你懂得懷疑、驗證、與重述。
